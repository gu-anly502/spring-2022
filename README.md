---
title: "ANLY502 Big Data and Cloud Computing Git Repo"
subtitle: "Georgetown University, Spring 2022"
output:
  html_document: default
  md_document:
    variant: gfm
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all") })
---


**This page is effective as of `r strftime(Sys.time(), "%A,  %B %d, %Y at %I:%M %p", tz = "America/New_York")`**

## Course Information

-   **Instructor:**

    -   Anderson Monken (anderson.monken at georgetown.edu)

-   **TA's:**

    -   Aashika Padmanabhan (ap1775 at georgetown.edu)
    -   Tianyi Xu (tx52 at georgetown.edu)

-   **Class Schedule:**

    -   Lecture meets Wednesdays 6:00-7:30 pm

        -   Zoom link on Canvas
        -   Lecture format will always be virtual and synchronous attendance is required

    -   Lab meets Thursdays 6:30-7:20pm

        -   Zoom link on Canvas
        -   Lab format will be virtual in the first few weeks and remain virtual based on COVID-19 conditions. In-person sessions will be held in Healy 103. In-person labs will be announced with at least 24 hours notice.
        -   Lab synchronous attendance is required

-   [Canvas Site](https://georgetown.instructure.com/courses/142215)
- [Syllabus](https://georgetown.instructure.com/courses/142215/assignments/syllabus)

## Course Description

Data is everywhere! Many times, the data is just too big to analyze
with traditional programming libraries on your laptop. That is where
cloud providers and distributed computation save the day. This is a
hands-on, practical workshop-style course about using cloud computing
resources to do analysis and manipulation of big data datasets that are
too large to fit on a single machine and/or analyzed with traditional
tools. The course will focus on Spark, the Hadoop Ecosystem, and other
tools.

You will understand how to ingest the data, and then massage, clean,
transform, analyze, and model it within the context of big data
analytics. You will be able to think more programmatically and logically
about your big data needs, tools, and issues.

## Course Objectives

By the end of the term, you will be able to:

-   Operate big data tools and cloud infrastructure, including Spark
    (with all of Spark's APIs), MapReduce, Hadoop, and other tools in the
    big data ecosystem

-   Develop strategies to break down large problems and datasets into manageable pieces

-   Recognize and use ancillary tools that support big data processing, including git and the Linux command line

-   Setup and manage big data infrastructure and tools in the cloud on Amazon Web Services (and some Microsoft Azure)

-   Identify broad spectrum resources and documentation to remain current with big data tools and developments

-   Communicate and interpret the big data analytics results through written and verbal methods

-   Execute a big data analytics exercise from start to finish: ingest, wrangle, clean, analyze, store, and present

## Course Calendar

[Link here (requires GU credentials)](https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8k5uBzLOq3op0lBIDDJkMpvpR9UCH9o6cD6qztWdoHPPNY9OxDl3wReMo2oJhO9xJNLs0ZrFnaNJE/pubhtml?gid=0&amp;single=true&amp;widget=true&amp)