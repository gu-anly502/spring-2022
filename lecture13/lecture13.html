<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 13 - PySpark Workflows</title>
    <meta charset="utf-8" />
    <meta name="author" content="Anderson Monken" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <link href="libs/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lecture 13 - PySpark Workflows
## ANLY 502 - Big Data and Cloud Computing
### Anderson Monken
### Spring 2022

---











.pull-left[

## Looking Back

* Spark DataFrames
* Harnessing data skills at scale
* Building models using big data
* Processing text at scale
* Streaming data at scale

## Upcoming

* Cloud workflows
* RAPIDS/Dask/Ray/etc.

]

.pull-right[

## Admin

* AWS Academy Courses
* Deadlines
* Review of Lab, Project
* Review of Containers and Lambda

## Today

* PySpark Automated Jobs
* AWS Glue
    * Interactive Notebooks
    * Crawlers for Data Stores
* PySpark Pandas UDFs


]

---

## AWS Academy

* Credit limit - $100

* Course numbers:
    * Course #1 - 12142
    * Course #2 - 12143
    * Course #3 - 12144
    * Course #4 - 12147

STAY CURRENT COURSE UNLESS YOU HAVE RUN OUT OF CREDITS OR &gt;$90 USED!

Note that you will have to repeat several setup steps:

* security group
* EC2 keypair uploading (the AWS part only)
* any data uploading or copying to S3 buckets (bucket creation as necessary)
* EMR configuration

---

## Deadlines

* Project EDA Discussion Responses - Due by 4/10 11:59 pm (+24 hour penalty-free) - [link](https://georgetown.instructure.com/courses/142215/discussion_topics/866838)
* Lab 12 Deliverable - Due by 4/13 11:59 pm (+24 hour penalty-free) - [link](https://georgetown.instructure.com/courses/142215/assignments/722126)
* ***Project NLP Assignment*** - Due by 4/15 11:59 pm (+24 hour penalty-free) - [link](https://georgetown.instructure.com/courses/142215/assignments/722142)
* **Project Presentation** - Due by 4/21 noon (NO EXTENSION!) - [link](https://georgetown.instructure.com/courses/142215/assignments/722146)
* **Project ML Assignment** - Due by 4/23 11:59 pm (+24 hour penalty-free) - [link](https://georgetown.instructure.com/courses/142215/assignments/722145)
* Project Revise and Resubmit Discussion - Due by 4/24 11:59 pm (+24 hour penalty-free) - [link](https://georgetown.instructure.com/courses/142215/discussion_topics/866840)
* Project Final Portfolio Submission - Due by 5/3 11:59 pm (NO EXTENSION!) CANNOT BE LATE! - [link](https://georgetown.instructure.com/courses/142215/assignments/722146)

---

## Questions on Lab 12?

* https://github.com/gu-anly502/lab-lambda-docker

---

## Review of Lab 11

* https://github.com/bigdatateaching/lab-spark-structuredstreaming

Live walkthrough with solution notebook!

---

## Project EDA Assignment/Discussion Review

Major points:

- You must analyze all of your data! Taking a smaller slice of data is good for testing, but that is not what you present at the end of your analysis
- The data is not perfect!! Missing original posts, not all the topics you want! **This happens all the time**
- Very few people saved the final dataset that they made in their assignment. This means you now have to re-process all your data! That means more computation!
- Issues with converting unix timestamp into datetime format. What options do we have to convert the data type?

Discussion points:

- Writing is critical! You must be descriptive, persuasive, and elaborate
- Your audience are the employers you have not met yet
- Going to be taking off points for short introductions

---

## Project NLP Assignment Overview

* https://github.com/gu-anly502/project-nlp-assignment-AndersonMonken

* Use the [discussion board](https://georgetown.instructure.com/courses/142215/modules/items/2542882) for Module 13 to ask questions on the project NLP work!

---

## Project Presentation Overview

* Presentations on April 21 and April 28
* 3 minute presentation and follow-up Q&amp;A
* https://georgetown.instructure.com/courses/142215/assignments/722146
* In-person attendence required! Participation critical!

---

## Project ML Assignment Overview

* https://github.com/gu-anly502/project-ml-assignment-AndersonMonken

* Use the [discussion board](https://georgetown.instructure.com/courses/142215/discussion_topics/819196) for Module 14 to ask questions on the project ML work!

---

## Project Final Portfolio Overview

* https://github.com/gu-anly502/project-final-portfolio-AndersonMonken

* Use the [discussion board](https://georgetown.instructure.com/courses/142215/modules/items/2542884) for Module 15 to ask questions on the final project!

---

## Project Check-In

- What are your major blockers?
- Technical problems?
- Are there skills I can review to help your work?
- Do you need to brainstorm next steps of your project?
- Issues with output of analysis?

---

class: inverse, middle, center

# Review of Containers and Lambda

---

## Docker

.center[
&lt;img src="img/docker-container-arch.PNG" width=300&gt;
]


* Package and run applications in isolated environment
* Pass your application to others to execute
* Great for production work, not as much for developmental work
* Docker like a tiny virtual machine (VM) without any of the OS

[docker basics](https://docs.docker.com/get-started/overview/)

---

## Docker vs. VM

.center[
&lt;img src="img/vm-vs-container.PNG" width=500&gt;
]

---

## Docker for Python jobs

Basic needs:
- Dockerfile that sets up environment
- Application code to execute
- List of packages to install

[Walkthrough](https://docs.docker.com/language/python/build-images/)

.center[
&lt;img src="img/taxonomy-docker.PNG" width=500&gt;
]

---

## Steps for Docker

1. Write your Dockerfile

```
FROM python:3.8-slim-buster

WORKDIR /app

COPY requirements.txt requirements.txt
RUN pip3 install -r requirements.txt

COPY . .

CMD [ "python3", "-m" , "flask", "run", "--host=0.0.0.0"]

```

---

## Steps for Docker

2. Build the docker image using a tag and version number `docker build ./ -t docker-tag-name:1.0`. Read about docker building options [here](https://docs.docker.com/engine/reference/commandline/build/).

3. Check your docker images in your local file system using `docker images`

4. Test your docker image using `docker run -it docker-tag-name`. Read about the flags [here](https://docs.docker.com/engine/reference/run/). The `i` is to keep STDIN open, the `t` is for pseudo-TTY mode (shell).

5. Deploy your docker image somewhere!

---

## Docker can be used with EMR!

[AWS examples](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-docker.html)

---

## Lambda Details

![](img/lambda-example.png)

* Micro executions without dealing with any hardware "serverless" computation
* Can run many copies of code depending on number of requests or files
* Pricing based on RAM and time used - 
https://aws.amazon.com/lambda/pricing/
* Max execution time - 15 minutes
* Max RAM - 10 GB

---

## Lambda coding choices

Levels of Lambda complexity:

1. Basic code
2. Zip archive
3. Docker Containers

---

## Connecting multiple Lambdas together

[Connecting multiple lambda using AWS Step Functions](https://medium.com/zenofai/create-an-etl-solution-using-aws-step-functions-lambda-and-glue-302623bc2fea)

---


## Dealing with serverless cloud costs

.pull-left[
* Sometimes you have to write custom cloud code to clear always running services [link](https://blog.jayway.com/2018/07/03/aws-glue-dev-endpoint-deleter/)

* Nightmare serverless stories [link](https://thenewstack.io/serverless-horror-stories/)

1. Lambda scaling gone wrong - infinite invocation loop within an S3 bucket that created a $200 bill within minutes!
2. Picking the use case with varying usage - consistent high usage better to run on a server!

* Tracing the cause of delays in AWS [link](https://blog.thundra.io/enhancing-distributed-tracing-with-business-context?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform)
]

.pull-right[
&lt;img src="img/trace-serverless.PNG" width=300&gt;
]

---


.center[
&lt;img src="img/aws-problems.PNG" width=600&gt;
]


---

class: inverse, middle, center

# PySpark Automated Jobs

---

## How do we make our PySpark job automated?

* How do we slice the data so that it is automated?
* What would the pipeline look like?
* How does all the data get combined together?

---

## Using EMR Actions

* Recall the use of Hadoop Streaming "Steps" with EMR
* Using spark-submit command in EMR - [link](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-submit-step.html)

.pull-right[
&lt;img src="img/spark-submit-emr.PNG" width=500&gt;
]

---

class: inverse, middle, center

# AWS Glue

---

.center[
&lt;img src="img/aws-hello-meme.PNG" width=800&gt;
]

---

.center[
&lt;img src="img/glue-how-it-works.PNG" width=800&gt;
]

[link](https://docs.aws.amazon.com/glue/latest/dg/components-key-concepts.html)

---

## AWS Glue Overview

.pull-left[
* Serverless data integration service
* Runs on top of Spark for certain pieces!
* Many associated products now
* The fundamentals go back to effective ETL
* Read more about how it works [here](https://docs.aws.amazon.com/glue/latest/dg/how-it-works.html)
]

.pull-right[
&lt;img src="img/aws-orchestration.PNG" width=800&gt;
]

---

## Example

.center[
&lt;img src="img/sample-glue-process-diagram1.JPG" width=800&gt;
]

---

## AWS Glue ETL Job Types

* Apache Spark job
* Spark Streaming job
* Python shell job

#### Glue is specialized
* Amazon made its own dataframe object called dynamic frames. Read more [here](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-samples-legislators.html)
* You can build a serverless data lake using Glue - [link](https://aws.amazon.com/blogs/big-data/build-and-automate-a-serverless-data-lake-using-an-aws-glue-trigger-for-the-data-catalog-and-etl-jobs/)

---

## AWS Glue Costs

* Cost based on data processing units (DPUs)
* DPU means 4 vCPU and 16GB of ram. Like a 2xlarge EC2!
* $0.44 per DPU-Hour, billed per second, with a 1-minute minimum

Read details here - [link](https://aws.amazon.com/glue/pricing/)

---

## AWS Glue Demo

* Interactive Glue notebooks are now possible! - [link](https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html
)
* Note, that they get really expensive! 
* 5 DPUs by default so \$2.20 per hour.... or \$100 if you forget to turn it off over the weekend

---

## AWS Glue Studio

* Demo on Lending Club data

https://us-east-1.console.aws.amazon.com/gluestudio/home?region=us-east-1

* Visual component
    * S3 bucket
    * Transformation
    * Filter
    * Push button interface
    
* Script component

---

## AWS Glue Crawlers

.pull-left[
&lt;img src="img/crawler-diagram.PNG" width=300&gt;
]

.pull-right[
Place the crawler where it can crawl - [link](https://docs.aws.amazon.com/glue/latest/dg/crawler-data-stores.html)

* Demo on AWS Glue website!
* How is it similar to reading in a file from PySpark or Hive?
]

---

## AWS Glue Data Catalog Example

* Populating the catalog - [link](https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html)

.center[
&lt;img src="img/sample-glue-process-diagram3.PNG" width=800&gt;
]

---

## Glue Medical Example

https://github.com/aws-samples/aws-glue-samples/blob/master/examples/data_cleaning_and_lambda.md
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
